import { NextResponse } from 'next/server'
import OpenAI from 'openai'
import { createPrompt, mapFormDataToPrompt, createFineTunePrompt, createContextualPrompt } from '../../../../lib/promptGenerator'
import { requireContentGeneration, handleAuthError } from '../../../../lib/authMiddleware'
import { incrementArticleUsage, incrementArticleAndTokenUsage, canUserGenerateContent } from '../../../../lib/usageTracker'
import { getUserPlanFromDB } from '../../../../lib/permissions'
import { clientPromise } from '../../../../lib/mongodb'

// Inicializar cliente de OpenAI
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
})

// Validar que tenemos API key
if (!process.env.OPENAI_API_KEY) {
  console.error('âŒ OPENAI_API_KEY no configurada')
}

export async function POST(request) {
  console.log('ðŸš€ Iniciando generaciÃ³n de artÃ­culo...')
  console.log('ðŸ”‘ API Key configurada:', !!process.env.OPENAI_API_KEY)
  
  // Validar API key temprano
  if (!process.env.OPENAI_API_KEY) {
    console.error('âŒ OPENAI_API_KEY no estÃ¡ configurada')
    return NextResponse.json(
      { error: 'ConfiguraciÃ³n del servidor incompleta' },
      { status: 500 }
    )
  }
  
  try {
    console.log('ðŸ” Verificando autenticaciÃ³n y permisos...')
    // Verificar permisos y autenticaciÃ³n
    const authResult = await requireContentGeneration(request, 'article')
    console.log('ðŸ” Resultado autenticaciÃ³n:', authResult.success ? 'OK' : 'FAIL', authResult.error || '')
    
    if (!authResult.success) {
      console.log('âŒ Error de autenticaciÃ³n:', authResult.error)
      return handleAuthError(authResult)
    }
    
    const user = authResult.user
    const formData = await request.json()
    
    // Validar datos requeridos
    if (!formData.topic || !formData.tone || !formData.length || !formData.objective) {
      console.log('âŒ Faltan datos requeridos:', {
        topic: !!formData.topic,
        tone: !!formData.tone,
        length: !!formData.length,
        objective: !!formData.objective
      })
      return NextResponse.json(
        { error: 'Faltan datos requeridos' },
        { status: 400 }
      )
    }

    console.log('ðŸ”„ Mapeando datos del formulario...')
    // Mapear datos del formulario
    let mappedData
    try {
      mappedData = mapFormDataToPrompt(formData)
      console.log('âœ… Datos mapeados correctamente')
    } catch (mappingError) {
      console.error('âŒ Error mapeando datos:', mappingError)
      return NextResponse.json(
        { error: 'Error procesando datos del formulario' },
        { status: 400 }
      )
    }
    
    // Verificar si tenemos modelo fine-tuned configurado
    const finetunedModel = process.env.OPENAI_FINETUNED_MODEL
    console.log('ðŸ¤– Modelo fine-tuned configurado:', !!finetunedModel)
    console.log('ðŸ¤– Valor de OPENAI_FINETUNED_MODEL:', finetunedModel || 'NO CONFIGURADO')
    
    let generatedContent
    let response
    let generationMethod = 'unknown'
    
    console.log('ðŸ”„ Iniciando generaciÃ³n con OpenAI...')
    
    if (finetunedModel) {
      // Usar modelo fine-tuned (dos pasos)
      console.log('Usando modelo fine-tuned:', finetunedModel)
      
      try {
        // Usar fine-tune directamente para generar el artÃ­culo completo
        const fineTunePrompt = `TONO: ${formData.tone}
TEMA: ${formData.topic}
ENFOQUE: ${formData.professionalFocus}
EXTENSIÃ“N: ${formData.length}
OBJETIVO: ${formData.objective}`
        
        console.log('Prompt para fine-tune completo:', fineTunePrompt)
        
        response = await openai.chat.completions.create({
          model: finetunedModel,
          messages: [
            {
              role: "user",
              content: fineTunePrompt
            }
          ],
          max_tokens: 2000,
          temperature: 0.7
        })
        
        generatedContent = response.choices[0].message.content
        generationMethod = 'fine-tuned direct'
        console.log('âœ… ArtÃ­culo generado directamente con FINE-TUNE:', generatedContent.substring(0, 200) + '...')
        console.log('ðŸŽ¯ MÃ‰TODO UTILIZADO: Fine-tuned model directo')
        console.log('ðŸ“Š Respuesta del fine-tune:', {
          model: finetunedModel,
          usage: response.usage,
          finish_reason: response.choices[0].finish_reason
        })
      } catch (finetuneError) {
        console.error('âŒ Error con modelo fine-tuned, usando fallback:', finetuneError)
        console.log('ðŸ”„ CAUSAS POSIBLES: Modelo no disponible, API error, o configuraciÃ³n incorrecta')
        // Fallback al mÃ©todo tradicional
        const prompt = createPrompt(mappedData)
        console.log('Prompt generado (fallback):', prompt)
        
        response = await openai.chat.completions.create({
          model: "gpt-4",
          messages: [
            {
              role: "user",
              content: prompt
            }
          ],
          max_tokens: 2000,
          temperature: 0.7
        })
        
        generatedContent = response.choices[0].message.content
        generationMethod = 'gpt-4 fallback (fine-tune error)'
        console.log('ðŸ”„ ArtÃ­culo generado con MÃ‰TODO TRADICIONAL (fallback)')
        console.log('ðŸŽ¯ MÃ‰TODO UTILIZADO: GPT-4 estÃ¡ndar (sin fine-tune)')
      }
    } else {
      // Usar mÃ©todo tradicional (fallback)
      console.log('âš ï¸ NO HAY MODELO FINE-TUNED - Usando modelo estÃ¡ndar gpt-4')
      const prompt = createPrompt(mappedData)
      console.log('Prompt generado:', prompt)
      
      response = await openai.chat.completions.create({
        model: "gpt-4",
        messages: [
          {
            role: "user",
            content: prompt
          }
        ],
        max_tokens: 2000,
        temperature: 0.7
      })
      
      generatedContent = response.choices[0].message.content
      generationMethod = 'gpt-4 standard (no fine-tune configured)'
      console.log('ðŸ”„ ArtÃ­culo generado con MÃ‰TODO TRADICIONAL')
      console.log('ðŸŽ¯ MÃ‰TODO UTILIZADO: GPT-4 estÃ¡ndar (sin fine-tune configurado)')
    }
    
    // Validar que se generÃ³ contenido
    if (!generatedContent || !response.choices || !response.choices[0] || !response.choices[0].message) {
      console.error('Error: No se generÃ³ contenido vÃ¡lido')
      return NextResponse.json(
        { error: 'No se pudo generar el contenido' },
        { status: 500 }
      )
    }
    
    // Procesar la respuesta para extraer artÃ­culos
    const articles = processGeneratedContent(generatedContent, formData.resultsCount || 1)
    
    // Validar que tenemos artÃ­culos antes de continuar
    if (!articles || articles.length === 0) {
      console.error('No se generaron artÃ­culos:', generatedContent)
      return NextResponse.json(
        { error: 'No se pudieron generar artÃ­culos vÃ¡lidos' },
        { status: 500 }
      )
    }

    // Incrementar contador de uso segÃºn el plan del usuario
    try {
      console.log('Obteniendo plan del usuario:', user.email)
      const userPlan = await getUserPlanFromDB(user.email)
      console.log('Plan obtenido:', userPlan)
      
      const tokensUsed = response.usage?.total_tokens || 0
      console.log('Tokens usados:', tokensUsed)
      
      if (userPlan && userPlan.id === 'trial') {
        // TRIAL: Solo incrementar artÃ­culos (3 mÃ¡ximo)
        console.log('Incrementando uso para usuario trial')
        await incrementArticleUsage(user.email)
      } else if (userPlan) {
        // PLANES PAGOS: Incrementar artÃ­culos y tokens
        console.log('Incrementando uso para usuario pagado')
        await incrementArticleAndTokenUsage(user.email, tokensUsed)
      } else {
        console.log('Usuario sin plan vÃ¡lido, permitiendo uso bÃ¡sico')
      }
      
      // Guardar artÃ­culos automÃ¡ticamente en la base de datos
      try {
        const client = await clientPromise
        const db = client.db(process.env.MONGODB_DB || 'miSaaS')
        const articlesCollection = db.collection('articles')
        
        console.log('Guardando artÃ­culos en la base de datos...')
        for (const article of articles) {
          const articleDoc = {
            userId: user.email,
            title: article.title,
            body: article.content,
            status: 'draft',
            template: 'ai-generated',
            metadata: {
              tone: mappedData.tone || 'profesional',
              length: mappedData.length || 'medio',
              keywords: [mappedData.topic].filter(Boolean),
              tags: [mappedData.objective].filter(Boolean),
              targetAudience: mappedData.targetAudience || mappedData.audience || 'profesionales',
              estimatedReadTime: Math.ceil(article.wordCount / 200) || 1,
              wordCount: article.wordCount,
              generationData: {
                createdAt: new Date(),
                professionalFocus: mappedData.professionalFocus,
                aspects: mappedData.aspects
              }
            },
            createdAt: new Date(),
            updatedAt: new Date()
          }
          
          await articlesCollection.insertOne(articleDoc)
          console.log('ArtÃ­culo guardado:', article.title)
        }
        console.log('Todos los artÃ­culos guardados correctamente')
      } catch (saveError) {
        console.error('Error guardando artÃ­culos:', saveError)
        // No fallar la respuesta si hay error al guardar
      }
      
      // Obtener informaciÃ³n actualizada de uso (sin fallar si hay error)
      let updatedUsageInfo = null
      try {
        updatedUsageInfo = await canUserGenerateContent(user.email, 'article')
      } catch (usageInfoError) {
        console.error('Error obteniendo info de uso:', usageInfoError)
      }
      
      return NextResponse.json({
        success: true,
        articles: articles,
        usage: response.usage || {},
        usageInfo: updatedUsageInfo,
        tokensUsed: tokensUsed,
        userPlan: userPlan?.id || 'unknown',
        generationMethod: generationMethod,
        finetunedModelConfigured: !!finetunedModel,
        finetunedModelName: finetunedModel || null
      })
    } catch (usageError) {
      console.error('Error tracking usage:', usageError)
      // No fallar la respuesta por error de tracking - devolver los artÃ­culos
      return NextResponse.json({
        success: true,
        articles: articles,
        usage: response.usage || {},
        error: 'Error tracking usage but content generated',
        generationMethod: generationMethod,
        finetunedModelConfigured: !!finetunedModel,
        finetunedModelName: finetunedModel || null
      })
    }

  } catch (error) {
    console.error('Error generando artÃ­culo:', error)
    console.error('Error details:', {
      message: error.message,
      code: error.code,
      status: error.status,
      stack: error.stack
    })
    
    // Manejar errores especÃ­ficos de OpenAI
    if (error.code === 'insufficient_quota') {
      return NextResponse.json(
        { error: 'LÃ­mite de API alcanzado', details: error.message },
        { status: 429 }
      )
    }
    
    if (error.code === 'invalid_api_key') {
      return NextResponse.json(
        { error: 'API Key invÃ¡lida', details: error.message },
        { status: 401 }
      )
    }
    
    if (error.code === 'model_not_found') {
      return NextResponse.json(
        { error: 'Modelo no encontrado', details: error.message },
        { status: 400 }
      )
    }
    
    return NextResponse.json(
      { 
        error: 'Error interno del servidor', 
        details: error.message,
        code: error.code 
      },
      { status: 500 }
    )
  }
}

// FunciÃ³n para procesar el contenido generado y separar los artÃ­culos
function processGeneratedContent(content, resultsCount) {
  const articles = []
  
  // Validar que tenemos contenido
  if (!content || typeof content !== 'string' || content.trim().length === 0) {
    console.error('Contenido generado estÃ¡ vacÃ­o o invÃ¡lido:', content)
    return []
  }
  
  try {
    if (resultsCount === 1 || !resultsCount) {
      // Un solo artÃ­culo - limpiar y formatear
      const cleanContent = cleanAndFormatContent(content)
      if (cleanContent && cleanContent.trim().length > 0) {
        articles.push({
          id: 1,
          title: extractTitle(cleanContent),
          content: cleanContent,
          wordCount: countWords(cleanContent)
        })
      }
    } else {
      // MÃºltiples artÃ­culos - separar por "---" o tÃ­tulos
      const articleSections = content.split(/---+/).filter(section => section.trim())
      
      if (articleSections.length === 0) {
        // Si no se separÃ³ correctamente, usar todo el contenido como un artÃ­culo
        const cleanContent = cleanAndFormatContent(content)
        if (cleanContent && cleanContent.trim().length > 0) {
          articles.push({
            id: 1,
            title: extractTitle(cleanContent),
            content: cleanContent,
            wordCount: countWords(cleanContent)
          })
        }
      } else {
        articleSections.forEach((section, index) => {
          if (section.trim()) {
            const cleanContent = cleanAndFormatContent(section.trim())
            if (cleanContent && cleanContent.trim().length > 0) {
              articles.push({
                id: index + 1,
                title: extractTitle(cleanContent),
                content: cleanContent,
                wordCount: countWords(cleanContent)
              })
            }
          }
        })
      }
    }
  } catch (processingError) {
    console.error('Error procesando contenido:', processingError)
    // Intentar devolver al menos el contenido bÃ¡sico
    if (content && content.trim().length > 0) {
      articles.push({
        id: 1,
        title: 'ArtÃ­culo Generado',
        content: content.trim(),
        wordCount: countWords(content)
      })
    }
  }
  
  return articles
}

// FunciÃ³n para limpiar y formatear el contenido
function cleanAndFormatContent(content) {
  if (!content || typeof content !== 'string') {
    return ''
  }
  
  try {
    return content
      .replace(/^#+\s*TÃ­tulo[:\s]*/gmi, '') // Remover "TÃ­tulo:" o "## TÃ­tulo:"
      .replace(/^#+\s*Gancho inicial[:\s]*/gmi, '') // Remover "Gancho inicial:"
      .replace(/^#+\s*Cuerpo[:\s]*/gmi, '') // Remover "Cuerpo:"
      .replace(/^#+\s*ConclusiÃ³n[:\s]*/gmi, '## ConclusiÃ³n\n\n') // Limpiar "ConclusiÃ³n:"
      .replace(/^#+\s*Hashtags[:\s]*/gmi, '') // Remover "Hashtags:"
      .replace(/\n{3,}/g, '\n\n') // Limitar saltos de lÃ­nea mÃºltiples
      .trim()
  } catch (error) {
    console.error('Error limpiando contenido:', error)
    return content || ''
  }
}

// FunciÃ³n para extraer el tÃ­tulo del contenido
function extractTitle(content) {
  if (!content || typeof content !== 'string') {
    return 'ArtÃ­culo Generado'
  }
  
  try {
    const titleMatch = content.match(/^#\s*(.+)$/m)
    return titleMatch ? titleMatch[1].trim() : 'ArtÃ­culo Generado'
  } catch (error) {
    console.error('Error extrayendo tÃ­tulo:', error)
    return 'ArtÃ­culo Generado'
  }
}

// FunciÃ³n para contar palabras
function countWords(text) {
  if (!text || typeof text !== 'string') {
    return 0
  }
  
  try {
    return text.split(/\s+/).filter(word => word.length > 0).length
  } catch (error) {
    console.error('Error contando palabras:', error)
    return 0
  }
}
